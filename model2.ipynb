{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU: {torch.cuda.get_device_name(0)} is available\")\n",
    "else:\n",
    "    print('\\nNo GPU available')\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_folder = \"meningioma-pickle/\"\n",
    "\n",
    "# Load pickled datasets\n",
    "with open(pickle_folder + \"X_train.pickle\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open(pickle_folder + \"Y_train.pickle\", \"rb\") as f:\n",
    "    Y_train = pickle.load(f)\n",
    "\n",
    "with open(pickle_folder + \"X_test.pickle\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open(pickle_folder + \"Y_test.pickle\", \"rb\") as f:\n",
    "    Y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data as tensors\n",
    "X_train = torch.tensor(X_train).float().unsqueeze(1)  # Add channel dimension\n",
    "# Ensure long type for classification\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test).float().unsqueeze(1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "\n",
    "        # Global average pooling layer\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 4)  # Output layer for 4 classes\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten for fully connected layers\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NeuralNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "bs = 96\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "# This loss function works for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    predicted = torch.argmax(y_pred, dim=1)  # Get predicted class\n",
    "    correct = (predicted == y_true).sum().item()\n",
    "    accuracy = correct / y_true.size(0)\n",
    "\n",
    "    print(\"y_pred:\", torch.argmax(y_pred, dim=1))\n",
    "    print(\"y_true:\", y_true)\n",
    "    return accuracy\n",
    "\n",
    "def calculate_metrics(y_pred, y_true):\n",
    "    # Convert predictions to class indices (max value)\n",
    "    predicted = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "    # Compute confusion matrix components\n",
    "    tp = ((predicted == 1) & (y_true == 1)).sum().item()  # True Positive\n",
    "    tn = ((predicted == 0) & (y_true == 0)).sum().item()  # True Negative\n",
    "    fp = ((predicted == 1) & (y_true == 0)).sum().item()  # False Positive\n",
    "    fn = ((predicted == 0) & (y_true == 1)).sum().item()  # False Negative\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return fp, tp, fn, tn, accuracy, precision, recall, specificity, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += calculate_accuracy(outputs, batch_Y)\n",
    "\n",
    "    epoch_loss /= len(train_loader)\n",
    "    epoch_accuracy /= len(train_loader)\n",
    "    writer.add_scalar(\"Loss/epoch\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/epoch\", epoch_accuracy, epoch)\n",
    "    print(\n",
    "        f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy * 100:.2f}%')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "model.eval()\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in test_loader:\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        test_accuracy += calculate_accuracy(outputs, batch_Y)\n",
    "\n",
    "test_accuracy /= len(test_loader)\n",
    "writer.add_scalar(\"Test Accuracy\", test_accuracy, num_epochs)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
